{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering with BERT and Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# If the above line produce errors make sure following dependencies are installed\n",
    "# conda install astunparse numpy ninja pyyaml setuptools cmake cffi typing_extensions future six requests dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0561b83a5f43b6ad2b476a5382af64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5ab7a26a4344ae99313fd741b1fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6544b9b5dc54e3e901d1e214666dd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f913ff06f4239a78148393def44c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f967d7a1f0fb46f4978a1d47a61e0183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the pipeline\n",
    "answerer = pipeline(task=\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context= '''\n",
    "Tea is an aromatic beverage prepared by pouring hot or boiling water over cured or fresh leaves of Camellia sinensis,\n",
    "an evergreen shrub native to China and East Asia. After water, it is the most widely consumed drink in the world. \n",
    "There are many different types of tea; some, like Chinese greens and Darjeeling, have a cooling, slightly bitter, \n",
    "and astringent flavour, while others have vastly different profiles that include sweet, nutty, floral, or grassy \n",
    "notes. Tea has a stimulating effect in humans primarily due to its caffeine content.\n",
    "\n",
    "The tea plant originated in the region encompassing today's Southwest China, Tibet, north Myanmar and Northeast India,\n",
    "where it was used as a medicinal drink by various ethnic groups. An early credible record of tea drinking dates to \n",
    "the 3rd century AD, in a medical text written by Hua Tuo. It was popularised as a recreational drink during the \n",
    "Chinese Tang dynasty, and tea drinking spread to other East Asian countries. Portuguese priests and merchants \n",
    "introduced it to Europe during the 16th century. During the 17th century, drinking tea became fashionable among the \n",
    "English, who started to plant tea on a large scale in India.\n",
    "\n",
    "The term herbal tea refers to drinks not made from Camellia sinensis: infusions of fruit, leaves, or other plant \n",
    "parts, such as steeps of rosehip, chamomile, or rooibos. These may be called tisanes or herbal infusions to prevent\n",
    "confusion with 'tea' made from the tea plant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8982149958610535, 'start': 148, 'end': 167, 'answer': 'China and East Asia'}\n"
     ]
    }
   ],
   "source": [
    "result = answerer(question=\"Where is tea native to?\", context=context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China and East Asia\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is tea native to? \n",
      " Answer:China and East Asia\n",
      "\n",
      "\n",
      "Question: When was tea discovered? \n",
      " Answer:3rd century AD\n",
      "\n",
      "\n",
      "Question: What is the species name for tea? \n",
      " Answer:Camellia sinensis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Where is tea native to?\",\n",
    "             \"When was tea discovered?\",\n",
    "             \"What is the species name for tea?\"]\n",
    "result = answerer(question= questions, context=context)\n",
    "for q,r in zip(questions,result):\n",
    "    print(f\"Question: {q} \\n Answer:{r['answer']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = '''\n",
    "The Golden Age of Comic Books describes an era of American comic books from the \n",
    "late 1930s to circa 1950. During this time, modern comic books were first published \n",
    "and rapidly increased in popularity. The superhero archetype was created and many \n",
    "well-known characters were introduced, including Superman, Batman, Captain Marvel \n",
    "(later known as SHAZAM!), Captain America, and Wonder Woman.\n",
    "Between 1939 and 1941 Detective Comics and its sister company, All-American Publications, \n",
    "introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash, \n",
    "Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman.[7] Timely Comics, \n",
    "the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch,\n",
    "the Sub-Mariner, and Captain America.[8]\n",
    "As comic books grew in popularity, publishers began launching titles that expanded \n",
    "into a variety of genres. Dell Comics' non-superhero characters (particularly the \n",
    "licensed Walt Disney animated-character comics) outsold the superhero comics of the day.[12] \n",
    "The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck,\n",
    "Roy Rogers and Tarzan.[13] It was during this era that noted Donald Duck writer-artist\n",
    "Carl Barks rose to prominence.[14] Additionally, MLJ's introduction of Archie Andrews\n",
    "in Pep Comics #22 (December 1941) gave rise to teen humor comics,[15] with the Archie \n",
    "Andrews character remaining in print well into the 21st century.[16]\n",
    "At the same time in Canada, American comic books were prohibited importation under \n",
    "the War Exchange Conservation Act[17] which restricted the importation of non-essential \n",
    "goods. As a result, a domestic publishing industry flourished during the duration \n",
    "of the war which were collectively informally called the Canadian Whites.\n",
    "The educational comic book Dagwood Splits the Atom used characters from the comic \n",
    "strip Blondie.[18] According to historian Michael A. Amundson, appealing comic-book \n",
    "characters helped ease young readers' fear of nuclear war and neutralize anxiety \n",
    "about the questions posed by atomic power.[19] It was during this period that long-running \n",
    "humor comics debuted, including EC's Mad and Carl Barks' Uncle Scrooge in Dell's Four \n",
    "Color Comics (both in 1952).[20][21]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What popular superheroes were introduced between 1939 and 1941? \n",
      " Answer:teen humor comics\n",
      "\n",
      "\n",
      "Question: What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company? \n",
      " Answer:Archie Andrews\n",
      "\n",
      "\n",
      "Question: What comic book characters were created between 1939 and 1941? \n",
      " Answer:Archie \n",
      "Andrews\n",
      "\n",
      "\n",
      "Question: What well-known characters were created between 1939 and 1941? \n",
      " Answer:Archie \n",
      "Andrews\n",
      "\n",
      "\n",
      "Question: What well-known superheroes were introduced between 1939 and 1941 by Detective Comics? \n",
      " Answer:Archie Andrews\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"What popular superheroes were introduced between 1939 and 1941?\",\n",
    "             \"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\",\n",
    "             \"What comic book characters were created between 1939 and 1941?\",\n",
    "             \"What well-known characters were created between 1939 and 1941?\",\n",
    "             \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"]\n",
    "result = answerer(question= questions, context=context1)\n",
    "for q,r in zip(questions,result):\n",
    "    print(f\"Question: {q} \\n Answer:{r['answer']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This Model is a fan of Archie Andrews. We will finetune the model on TyDiQA dataset to get proper answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning  QA with Transformrs Hugging-Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050891245cd3486e8c324b0d096d9be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd07e45133c4d07bbaba9c6b786f7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset tydiqa/primary_task (download: 1.82 GiB, generated: 5.62 GiB, post-processed: Unknown size, total: 7.44 GiB) to C:\\Users\\Sheraz\\.cache\\huggingface\\datasets\\tydiqa\\primary_task\\1.0.0\\b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36689cf4850f4251ad1c54778e2345fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32de3e3bd2cc4a658af1c51aa935b507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1eb5e62591a4586b158c9185da28d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/161M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a753f77fd6d44660b4fc2691e4eda21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383cd7240ab54f5699f121ac278e4e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206d880cc6da4a1f8fd266e3a50ec8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/58.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd90f1d58b3460790433ca5927666ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083265ac2bdc4d5f91e20668afeb6218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdacde0bbaf4a0499c8517fd9b59d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/166916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b967348d852407ea35dba97836e52f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/18670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tydiqa downloaded and prepared to C:\\Users\\Sheraz\\.cache\\huggingface\\datasets\\tydiqa\\primary_task\\1.0.0\\b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7c3daa50664167b575391f0efb68d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab54f03361947339fa99cb4f210c106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85f7c92059f40da8efd32a0258f5752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = load_dataset('tydiqa', 'primary_task')\n",
    "tydiqa_data = train_data.filter(lambda example: example['language']=='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (tydiqa_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "    num_rows: 9211\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tydiqa_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What mental effects can a mother experience after childbirth?\n",
      "\n",
      "Context (truncated): \n",
      "\n",
      "Postpartum depression (PPD), also called postnatal depression, is a type of mood disorder associated with childbirth, which can affect both sexes.[1][3] Symptoms may include extreme sadness, low energy, anxiety, crying episodes, irritability, and changes in sleeping or eating patterns.[1] Onset is typically between one week and one month following childbirth.[1] PPD can also negatively affect the newborn child.[2]\n",
      "\n",
      "While the exact cause of PPD is unclear, the cause is believed to be a combination of physi...\n",
      "\n",
      "Answer: Postpartum depression (PPD)\n"
     ]
    }
   ],
   "source": [
    "idx = 600\n",
    "# start index\n",
    "start_index = tydiqa_data['train'][idx]['annotations']['minimal_answers_start_byte'][0]\n",
    "# end index\n",
    "end_index = tydiqa_data['train'][idx]['annotations']['minimal_answers_end_byte'][0]\n",
    "\n",
    "print(\"Question: \" + tydiqa_data['train'][idx]['question_text'])\n",
    "print(\"\\nContext (truncated): \"+ tydiqa_data['train'][idx]['document_plaintext'][0:512] + '...')\n",
    "print(\"\\nAnswer: \" + tydiqa_data['train'][idx]['document_plaintext'][start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage_answer_candidate_index': [-1],\n",
       " 'minimal_answers_start_byte': [-1],\n",
       " 'minimal_answers_end_byte': [-1],\n",
       " 'yes_no_answer': ['NONE']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tydiqa_data['train'][0]['annotations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have to flatten the dataset to work with an object with a table structure instead of a dictionary structure. This step facilitates the pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Flattening the datasets\n",
    "flattened_train_data = tydiqa_data['train'].flatten()\n",
    "flattened_test_data =  tydiqa_data['validation'].flatten()\n",
    "# Selecting a Subset of Data\n",
    "flattened_train_data = flattened_train_data.select(range(3000))\n",
    "flattened_test_data = flattened_test_data.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving previous tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing samples using 3 steps\n",
    "# Step1 - If No answer to questions given context, use CLS to represent start of sequence.\n",
    "# Step2 - tokenizer can create misalignment between list of dataset tags and labels genereted by tokenizer. Therfor align the start and end indices\n",
    "# tokens associated with target answer word.\n",
    "# Step3 - Tokenizer can truncate a very long sequence.SO if start/end position of answer in None, assume truncation and assign maximum length of \n",
    "# tokenizer to those positions\n",
    "def process_samples(sample):\n",
    "    tokenized_data = tokenizer(sample['document_plaintext'], sample['question_text'], truncation='only_first', padding='max_length')\n",
    "    #Label impossible answers with id of CLS\n",
    "    input_ids = tokenized_data['input_ids']\n",
    "    cls_index= input_ids.index(tokenizer.cls_token_id)\n",
    "    \n",
    "    if sample[\"annotations.minimal_answers_start_byte\"][0] == -1:\n",
    "        start_position= cls_index\n",
    "        end_position = cls_index\n",
    "    else:\n",
    "        gold_text = sample['document_plaintext'][sample['annotations.minimal_answers_start_byte'][0]:sample['annotations.minimal_answers_end_byte'][0]]\n",
    "        start_char = sample['annotations.minimal_answers_start_byte'][0]\n",
    "        end_char = sample['annotations.minimal_answers_end_byte'][0]\n",
    "        \n",
    "        if sample['document_plaintext'][start_char-1:end_char-1] == gold_text:\n",
    "            start_char = start_char - 1\n",
    "            end_char = end_char - 1     # When the gold label is off by one character\n",
    "        elif sample['document_plaintext'][start_char-2:end_char-2] == gold_text:\n",
    "            start_char = start_char - 2\n",
    "            end_char = end_char - 2     # When the gold label is off by one character \n",
    "            \n",
    "        start_token = tokenized_data.char_to_token (start_char)\n",
    "        end_token = tokenized_data.char_to_token (end_char-1)\n",
    "        \n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_token is None:\n",
    "            start_token = tokenizer.model_max_length\n",
    "        if end_token is None:\n",
    "            end_token = tokenizer.model_max_length\n",
    "                \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c85fd73bbee41fa878dc17174d0e29968adcb16fb7d32a71d0bc99a4d86daf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
